{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb065ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip3 install pandas primer3-py pyfaidx biopython networkx matplotlib numpy scipy\n",
    "import pandas as pd\n",
    "from os import system\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "from time import sleep\n",
    "from Bio.Blast import NCBIWWW\n",
    "from Bio.Blast import NCBIXML\n",
    "from glob import glob\n",
    "from os import remove, mkdir\n",
    "\n",
    "import primer3\n",
    "from pyfaidx import Fasta\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fastq = 'sample.fastq' # Input fastq file name\n",
    "quality = 0.95 # Define minimal quality Phred score\n",
    "minSize = 50 # Define the minimum size required for a sequenced read to be utilized in the de novo assembly process, after trimming its ends if necessary\n",
    "minOverlap = 20 # Define minimal overlap required between two different sequences to be De-Novo assembled together\n",
    "\n",
    "# Phred quality score\n",
    "phredict = {'!': 1.0,\n",
    " '\"': 0.794328,\n",
    " '#': 0.630957,\n",
    " '$': 0.501187,\n",
    " '%': 0.398107,\n",
    " '&': 0.316228,\n",
    " \"'\": 0.251189,\n",
    " '(': 0.199526,\n",
    " ')': 0.158489,\n",
    " '*': 0.125893,\n",
    " '+': 0.1,\n",
    " ',': 0.079433,\n",
    " '-': 0.063096,\n",
    " '.': 0.050119,\n",
    " '/': 0.039811,\n",
    " '0': 0.031623,\n",
    " '1': 0.025119,\n",
    " '2': 0.019953,\n",
    " '3': 0.015849,\n",
    " '4': 0.012589,\n",
    " '5': 0.01,\n",
    " '6': 0.007943,\n",
    " '7': 0.00631,\n",
    " '8': 0.005012,\n",
    " '9': 0.003981,\n",
    " ':': 0.003162,\n",
    " ';': 0.002512,\n",
    " '<': 0.001995,\n",
    " '=': 0.001585,\n",
    " '>': 0.001259,\n",
    " '?': 0.001,\n",
    " '@': 0.000794,\n",
    " 'A': 0.000631,\n",
    " 'B': 0.000501,\n",
    " 'C': 0.000398,\n",
    " 'D': 0.000316,\n",
    " 'E': 0.000251,\n",
    " 'F': 0.0002,\n",
    " 'G': 0.000158,\n",
    " 'H': 0.000126,\n",
    " 'I': 0.0001,\n",
    " 'J': 7.9e-05,\n",
    " 'K': 6.3e-05}\n",
    "\n",
    "# Extracting high quality sequences from the input fastq file\n",
    "n = 0\n",
    "open('sequences.txt', 'w').write('')\n",
    "with open(fastq, 'r', encoding = 'utf-8-sig') as f:\n",
    "    current_sequence = ''\n",
    "    for line in f:\n",
    "        n += 1\n",
    "        if n == 2:\n",
    "            current_sequence = line.strip()\n",
    "        if n == 4:\n",
    "            phreds = [phredict[i] for i in line.strip()]\n",
    "            df = pd.DataFrame()\n",
    "            df['Sequence'] = [i for i in current_sequence]\n",
    "            df['Phred'] = phreds\n",
    "            high_quality_sequence = ''.join(df[df['Phred'] <= quality]['Sequence'].tolist())\n",
    "            if high_quality_sequence not in current_sequence:\n",
    "                continue\n",
    "            elif len(high_quality_sequence) < minSize:\n",
    "                continue\n",
    "            else:\n",
    "                open('sequences.txt', 'a').write(high_quality_sequence + '\\n')\n",
    "            n = 0\n",
    "\n",
    "sequences = [i.strip() for i in list(set(open('sequences.txt', 'r').read().split('\\n'))) if len(i) > 2]\n",
    "sorted(sequences)\n",
    "open('sequences.txt', 'w').write('\\n'.join(sequences))\n",
    "total_len = sum([len(i) for i in sequences])\n",
    "As = round(sum([i.count('A') for i in sequences]) / total_len * 100, 2)\n",
    "Ts = round(sum([i.count('T') for i in sequences]) / total_len * 100, 2)\n",
    "Cs = round(sum([i.count('C') for i in sequences]) / total_len * 100, 2)\n",
    "Gs = round(sum([i.count('G') for i in sequences]) / total_len * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cbc37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alignment and assembly methods\n",
    "def right_overlap(genome, sequence):\n",
    "    overlaps = []\n",
    "    for n in range(len(sequence) + 1):\n",
    "        if genome.endswith(sequence[:n]):\n",
    "            overlap = sequence[:n]\n",
    "            if len(overlap) != 0:\n",
    "                overlaps.append(sequence[:n])\n",
    "    if len(overlaps) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return len(overlaps[-1])\n",
    "\n",
    "def left_overlap(genome, sequence):\n",
    "    overlaps = []\n",
    "    for n in range(1, len(sequence)):\n",
    "        if genome.startswith(sequence[-n:]):\n",
    "            overlap = sequence[-n:]\n",
    "            if len(overlap) != 0:\n",
    "                overlaps.append(sequence[-n:])\n",
    "    if len(overlaps) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return len(overlaps[-1])\n",
    "\n",
    "def assemble(n):\n",
    "    sequences = [i for i in open('sequences.txt', 'r').read().split('\\n') if len(i) > minOverlap]\n",
    "    print(n + 1)\n",
    "    #system('echo ' + str(n))\n",
    "    genome = sequences[n]\n",
    "    goback_genome = []\n",
    "    goback_tracker = 0\n",
    "    shortening_tracker = 0\n",
    "    track_len_sequences = [0]\n",
    "    max_tries_for_sequence = 5\n",
    "    genome_with_junctions = genome\n",
    "    assemblies = []\n",
    "    max_tries = len(sequences)\n",
    "    tries = 0\n",
    "    while (len(sequences) != 0) or (tries != max_tries):\n",
    "        tries += 1\n",
    "        if goback_tracker > 0:\n",
    "            goback_tracker += -1\n",
    "        track_len_sequences.append(len(sequences))\n",
    "        if (len(track_len_sequences) == max_tries_for_sequence):\n",
    "            if len(set(track_len_sequences)) == 1:\n",
    "                try:\n",
    "                    genome = goback_genome[-1]\n",
    "                    goback_genome = goback_genome[:-1]\n",
    "                    goback_tracker += 2\n",
    "                    if goback_tracker > 10:\n",
    "                        break\n",
    "                except:\n",
    "                    break\n",
    "            track_len_sequences = [len(sequences)]\n",
    "        \n",
    "        maxLeft = 0\n",
    "        maxLeftSequence = ''\n",
    "        \n",
    "        for sequence in sequences:\n",
    "            if sequence in genome:\n",
    "                sequences.remove(sequence)\n",
    "            else:\n",
    "                lefts = [sequence, sequence[::-1], sequence.replace('A','t').replace('C','g').replace('T','a').replace('G','c').upper(), sequence.replace('A','t').replace('C','g').replace('T','a').replace('G','c').upper()[::-1]]\n",
    "                for left in lefts:\n",
    "                    left = left_overlap(genome, sequence)\n",
    "                    if left > maxLeft:\n",
    "                        maxLeft = left\n",
    "                        maxLeftSequence = sequence\n",
    "        if maxLeft >= minOverlap:\n",
    "            genome = maxLeftSequence[:-maxLeft] + genome\n",
    "            genome_with_junctions = maxLeftSequence[:-maxLeft] + '-' + genome_with_junctions\n",
    "            sequences.remove(maxLeftSequence)\n",
    "        \n",
    "        maxRight = 0\n",
    "        maxRightSequence = ''\n",
    "    \n",
    "        for sequence in sequences:\n",
    "            if sequence in genome:\n",
    "                sequences.remove(sequence)\n",
    "            else:\n",
    "                rights = [sequence, sequence[::-1], sequence.replace('A','t').replace('C','g').replace('T','a').replace('G','c').upper(), sequence.replace('A','t').replace('C','g').replace('T','a').replace('G','c').upper()[::-1]]\n",
    "                for right in rights:\n",
    "                    right = right_overlap(genome, sequence)\n",
    "                    if right > maxRight:\n",
    "                        maxRight = right\n",
    "                        maxRightSequence = sequence\n",
    "        if maxRight >= minOverlap:\n",
    "            goback_genome.append(genome)\n",
    "            genome = genome + maxRightSequence[maxRight:]\n",
    "            genome_with_junctions = genome_with_junctions + '-' + maxRightSequence[maxRight:]\n",
    "            sequences.remove(maxRightSequence)\n",
    "        assemblies.append([genome, genome_with_junctions])\n",
    "\n",
    "        if len(assemblies) > 1:\n",
    "            if len(assemblies[-1][0]) > len(assemblies[-2][0]):\n",
    "                shortening_tracker = 0\n",
    "            else:\n",
    "                shortening_tracker += 1\n",
    "            if shortening_tracker == 10:\n",
    "                break\n",
    "    \n",
    "    # remove subsequences\n",
    "    if len(assemblies) != 0:\n",
    "        seqs = [i[0] for i in assemblies]\n",
    "        keep = []\n",
    "        for n, seq1 in enumerate(seqs):\n",
    "            count = 0\n",
    "            for seq2 in seqs:\n",
    "                if seq1 in seq2 and seq1 != seq2:\n",
    "                    count += 1\n",
    "                if count == 2:\n",
    "                    break\n",
    "            if count < 2:\n",
    "                keep.append(n)\n",
    "        assemblies = [assemblies[i] for i in keep]\n",
    "\n",
    "    # remove duplicates\n",
    "    if len(assemblies) != 0:\n",
    "        df = pd.DataFrame()\n",
    "        df['genome'] = [i[0] for i in assemblies]\n",
    "        df['genome_with_junctions'] = [i[1] for i in assemblies]\n",
    "        df.drop_duplicates(subset=['genome'], keep = 'first', inplace = True)\n",
    "    return df\n",
    "\n",
    "#generating results dataframe, removing duplicares and genomes that are sub-strings of other genomes\n",
    "filtered_sequences = [i for i in open('sequences.txt', 'r').read().split('\\n') if len(i) > minOverlap]\n",
    "print(f'Assembling {len(filtered_sequences)} sequences') \n",
    "assemblies = [assemble(n) for n in range(len(filtered_sequences))]\n",
    "df = pd.concat(assemblies).reset_index(drop = True).drop_duplicates(subset = ['genome'], keep = 'first')\n",
    "df.sort_values(by = 'genome', key = lambda x: x.str.len(), ascending = False, inplace = True)\n",
    "df = df[df['genome'].apply(lambda x : len(x) > 3 * len(filtered_sequences[0]))]\n",
    "gs = df['genome'].tolist()\n",
    "dups = []\n",
    "for n,g in enumerate(gs):\n",
    "    if n == 0 or g not in gs[n-1]:\n",
    "        dups.append(n)\n",
    "df = df.iloc[dups].reset_index(drop=True)\n",
    "df.to_csv('result.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd033674-7cce-4a2d-945e-b6269124966f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NCBI BLAST search for in-silico validation\n",
    "df  = pd.read_csv('result.csv').head()\n",
    "n = 0\n",
    "def blastn_search(seq):\n",
    "    global n\n",
    "    n += 1\n",
    "    print(n)\n",
    "    try:\n",
    "        result_handle = NCBIWWW.qblast('blastn', 'nt', seq)\n",
    "        sleep(10)\n",
    "        result = result_handle.read()\n",
    "        output_file = result.split('<BlastOutput_query-ID>Query_')[1].split('<')[0] + '_blast_output.xml'\n",
    "        open(output_file, 'w').write(result)\n",
    "        with open(output_file, 'r') as blast_output:\n",
    "            blast_records = NCBIXML.parse(blast_output)\n",
    "            for blast_record in blast_records:\n",
    "                for alignment in blast_record.alignments:\n",
    "                    for hsp in alignment.hsps:\n",
    "                        title = alignment.title\n",
    "                        identity = round(hsp.match.count('|')/len(hsp.query) * 100, 2)\n",
    "                        e_value = round(hsp.expect, 5)\n",
    "                        return (title, identity, e_value)\n",
    "    except:\n",
    "        return ('','','')\n",
    "df['BLASTn'] = df['genome'].apply(blastn_search)\n",
    "for output_file in glob('*_blast_output.xml'):\n",
    "    remove(output_file)\n",
    "df['BLASTn-Result'] = df['BLASTn'].str[0]\n",
    "df['BLASTn-Identity_(%)'] = df['BLASTn'].str[1]\n",
    "df['BLASTn-E_value'] = df['BLASTn'].str[2]\n",
    "df.to_csv('result.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4ad9a0-d03b-4ac0-bc21-fdabc4fe9b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating Sanger sequencing assays for molecular validation\n",
    "def calculatePrimers(sequence):\n",
    "    primers = primer3.design_primers(\n",
    "        {\n",
    "            'SEQUENCE_ID': 'an_id',\n",
    "            'SEQUENCE_TEMPLATE': sequence,\n",
    "            'SEQUENCE_TARGET' : [350,100]\n",
    "        },\n",
    "        {\n",
    "            'PRIMER_TASK': 'generic',\n",
    "            'PRIMER_PICK_LEFT_PRIMER': 1,\n",
    "            'PRIMER_PICK_INTERNAL_OLIGO': 0,\n",
    "            'PRIMER_PICK_RIGHT_PRIMER': 1,\n",
    "            'PRIMER_NUM_RETURN': 10,\n",
    "            'PRIMER_OPT_SIZE': 20,\n",
    "            'PRIMER_MIN_SIZE': 18,\n",
    "            'PRIMER_MAX_SIZE': 27,\n",
    "            'PRIMER_OPT_TM': 58.0,\n",
    "            'PRIMER_MIN_TM': 57.0,\n",
    "            'PRIMER_MAX_TM': 63.0,\n",
    "            'PRIMER_MIN_GC': 20.0,\n",
    "            'PRIMER_MAX_GC': 80.0,\n",
    "            'PRIMER_MAX_POLY_X': 5,\n",
    "            'PRIMER_SALT_MONOVALENT': 50.0,\n",
    "            'PRIMER_DNA_CONC': 50.0,\n",
    "            'PRIMER_MAX_NS_ACCEPTED': 0,\n",
    "            'PRIMER_MAX_SELF_ANY': 12,\n",
    "            'PRIMER_MAX_SELF_END': 8,\n",
    "            'PRIMER_PAIR_MAX_COMPL_ANY': 12,\n",
    "            'PRIMER_PAIR_MAX_COMPL_END': 8,\n",
    "            'PRIMER_PRODUCT_SIZE_RANGE': [[100,800]]\n",
    "        }\n",
    "    )\n",
    "    return primers\n",
    "\n",
    "def generatePrimers(genome):\n",
    "    header = ['Primer left', 'Primer right', 'Primer left Tm (degrees Celcius)', 'Primer right Tm (degrees Celcius)', 'product_size (bp)', 'Product sequence']\n",
    "    lines = []\n",
    "    for i in range(0, len(genome) - 400, 400):\n",
    "        sequence = genome[i : i + 800]\n",
    "        try:\n",
    "            primers = calculatePrimers(sequence) \n",
    "            primer_left = primers['PRIMER_LEFT_1_SEQUENCE']\n",
    "            primer_right = primers['PRIMER_RIGHT_1_SEQUENCE']\n",
    "            primer_left_Tm = str(int(primers['PRIMER_LEFT_1_TM']))\n",
    "            primer_right_Tm = str(int(primers['PRIMER_RIGHT_1_TM']))\n",
    "            product_size = str(int(primers['PRIMER_PAIR_1_PRODUCT_SIZE']))\n",
    "            primer_right_flipped = primer_right.split(' ')[-1][::-1].replace('A','t').replace('T','a').replace('C','g').replace('G','c').upper()\n",
    "            product_sequence = primer_left.split(' ')[-1] + sequence.split(primer_left.split(' ')[-1])[1]\n",
    "            product_sequence = product_sequence.split(primer_right_flipped)[0] + primer_right_flipped\n",
    "            line = [primer_left, primer_right, primer_left_Tm, primer_right_Tm, product_size, product_sequence]\n",
    "            lines.append(line)\n",
    "        except:\n",
    "            continue\n",
    "    return lines\n",
    "\n",
    "df['PCR_validation_settings'] = df['genome'].apply(generatePrimers)\n",
    "df.to_pickle('results.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7d2987-9816-407b-8204-874f71da233a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Report generation\n",
    "\n",
    "# Nucleotide type distribution\n",
    "def nucPercentage(genome, As, Ts, Cs, Gs, output_filename):\n",
    "    gAs = round(genome.count('A') / len(genome) * 100, 2)\n",
    "    gTs = round(genome.count('T') / len(genome) * 100, 2)\n",
    "    gCs = round(genome.count('C') / len(genome) * 100, 2)\n",
    "    gGs = round(genome.count('G') / len(genome) * 100, 2)\n",
    "    labels = ['A', 'T', 'C', 'G']\n",
    "    sequence_1 = [As, Ts, Cs, Gs]\n",
    "    sequence_2 = [gAs, gTs, gCs, gGs]\n",
    "    \n",
    "    barWidth = 0.35\n",
    "    r1 = np.arange(len(sequence_1))\n",
    "    r2 = [x + barWidth for x in r1]\n",
    "    bars1 = plt.bar(r1, sequence_1, width = barWidth, color = 'blue', alpha = 0.7, label = 'Raw data')\n",
    "    bars2 = plt.bar(r2, sequence_2, width = barWidth, color = 'red', alpha = 0.7, label = 'Assembly')\n",
    "    \n",
    "    plt.xlabel('Nucleotides %')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Comparison of Nucleotide Percentage')\n",
    "    \n",
    "    for bar in bars1 + bars2:\n",
    "        yval = str(bar.get_height())\n",
    "        if len(yval) == 2:\n",
    "            yval += '.'\n",
    "        while len(yval) != 5:\n",
    "            yval += '0'\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, float(yval) + 0.5, yval + '%', ha = 'center', va = 'bottom')\n",
    "    plt.gca().axes.get_yaxis().set_visible(False)\n",
    "    plt.gca().spines['left'].set_visible(False)\n",
    "    for spine in plt.gca().spines.values():\n",
    "        spine.set_visible(False)\n",
    "    plt.xticks([r + barWidth/2 for r in range(len(sequence_1))], labels)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_filename, format = 'svg')\n",
    "    plt.clf()\n",
    "\n",
    "# De-Bruijn graph generation\n",
    "def de_bruijn(sequence, k, output_filename):\n",
    "    edges = []\n",
    "    for i in range(len(sequence) - k + 1):\n",
    "        edges.append((sequence[i:i+k-1], sequence[i+1:i+k]))\n",
    "    G = nx.DiGraph(edges)\n",
    "    pos = nx.spring_layout(G, k = 0.2)\n",
    "    nx.draw(G, pos, with_labels = True, node_size = 10, node_color = 'skyblue', font_size = 1, edge_color = \"gray\", width = 0.1, arrowsize = 0.1)\n",
    "    plt.title('De Bruijn Graph')\n",
    "    plt.savefig(output_filename, format = 'svg')\n",
    "    plt.clf()\n",
    "\n",
    "# HTML functions\n",
    "def P(text):\n",
    "    return '<P>' + text + '</P>'\n",
    "\n",
    "def H3(text):\n",
    "    return '<H3>' + text + '</H3>'\n",
    "\n",
    "# Report output file generation\n",
    "n = 0\n",
    "def generateReport(data):\n",
    "    global n\n",
    "    n += 1\n",
    "    genome = data['genome']\n",
    "    genome_with_junction = data['genome_with_junctions']\n",
    "    BLASTn_Result = data['BLASTn-Result']\n",
    "    BLASTn_Identity = data['BLASTn-Identity_(%)']\n",
    "    BLASTn_E_value = data['BLASTn-E_value']\n",
    "    PCRs = data['PCR_validation_settings']\n",
    "    path = 'Results/Prediction_' + str(n)\n",
    "    fasta = '>Prediction_' + str(n) + '\\n' + '\\n'.join(genome[i:i+70] for i in range(0, len(genome), 70))\n",
    "    fasta_with_junctions = '>Prediction_' + str(n) + '_with_alignment_junctions\\n' + '\\n'.join(genome_with_junction[i:i+70] for i in range(0, len(genome), 70))\n",
    "    try:\n",
    "        mkdir(path)\n",
    "        mkdir(path + '/assets')\n",
    "    except:\n",
    "        0\n",
    "    open(path + '/Prediction_' + str(n) + '.fasta', 'w').write(fasta)\n",
    "    Fasta(path + '/Prediction_' + str(n) + '.fasta')\n",
    "    open(path + '/Prediction_' + str(n) + '_with_junctions.fasta', 'w').write(fasta_with_junctions)\n",
    "    Fasta(path + '/Prediction_' + str(n) + '_with_junctions.fasta')\n",
    "    k = minSize\n",
    "    de_bruijn_path = path + '/assets/Prediction_' + str(n) + '_de_bruijn.svg'\n",
    "    de_bruijn(genome, k, de_bruijn_path)\n",
    "    nucPrecPath = path + '/assets/Prediction_' + str(n) + '_nucleotide_Percentages.svg'\n",
    "    nucPercentage(genome, As, Ts, Cs, Gs, nucPrecPath)\n",
    "    html = '<HTML>\\n'\n",
    "    html += '''<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>tab_title</title>\n",
    "    <style>\n",
    "        p.justified {\n",
    "            text-align: justify;\n",
    "            max-width: 500px;  /* This is just to make sure the paragraph is not too wide for demonstration purposes. */\n",
    "        }\n",
    "        body {\n",
    "            background-color: white;\n",
    "        }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "'''.replace('tab_title', 'Prediction_' + str(n))\n",
    "    html += H3('Sequences') + '\\n'\n",
    "    html += P(fasta.replace('\\n', '<br>')) + '\\n'\n",
    "    html += '\\n<br>\\n'\n",
    "    html += P(fasta_with_junctions.replace('\\n', '<br>')) + '\\n'\n",
    "    html += '\\n<br>\\n'\n",
    "    html += H3('BLAST Results') + '\\n'\n",
    "    html += P('Most similar sequence: ' + BLASTn_Result) + '\\n'\n",
    "    html += P('% Identity = ' + str(BLASTn_Identity)) + '\\n'\n",
    "    html += P('E-value = ' + str(BLASTn_E_value)) + '\\n'\n",
    "    html += '\\n<br>\\n'\n",
    "    html += H3('Recommended PCRs for valication:') + '\\n'\n",
    "    for PCR in PCRs:\n",
    "        html += P('Primer forward: ' + PCR[0] + ', Tm = ' + PCR[2] + '&deg;C') + '\\n'\n",
    "        html += P('Primer Reverse: ' + PCR[1] + ', Tm = ' + PCR[3] + '&deg;C') + '\\n'\n",
    "        html += P('Product length = ' + PCR[4] + 'bp') + '\\n'\n",
    "        html += P('Product sequence:') + '\\n'\n",
    "        product = '\\n'.join(PCR[5][i:i+70] for i in range(0, len(PCR[5]), 70))\n",
    "        html += P(product.replace('\\n', '<br>')) + '\\n'\n",
    "        html += '\\n<br>\\n'\n",
    "    html += '<img src=' + 'Prediction_' + str(n) + '/assets/Prediction_' + str(n) + '_nucleotide_Percentages.svg' + ' alt=\"Per-nucleotide statistics FASTQ vs. Assembly\">' + '\\n'\n",
    "    html += '<img src=' + 'Prediction_' + str(n) + '/assets/Prediction_' + str(n) + '_de_bruijn.svg' + ' alt=\"De Bruijn Graph\">' + '\\n'\n",
    "    html += '\\n</body>' + '\\n'\n",
    "    html += '\\n</HTML>'\n",
    "    open(path + '_Summary.html', 'w').write(html)\n",
    "try:\n",
    "    remove('Results')\n",
    "except:\n",
    "    0\n",
    "try:\n",
    "    mkdir('Results')\n",
    "except:\n",
    "    0\n",
    "df.apply(generateReport, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f034c15-86d1-47df-aafe-b0cf511bec78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
